{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9bd2cb",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "Het extract - transform - load concept is een veel voorkomend begrip in (big) data toepassingen en geeft het stappenplan weer van de levenscyclus van de data binnen je toepassing.\n",
    "Het concept bestaat uit drie stappen:\n",
    "* extract: zoeken van data, inlezen en validatie\n",
    "* transform: verwerken van data, data cleaning, aggregatie, groupering, filtering, ...\n",
    "* load: opslaan van de getransformeerde data in een file, database, datawarehouse, datalake, ...\n",
    "\n",
    "In de rest van deze notebook gaan we bestuderen hoe deze stappen uit te voeren met Spark.\n",
    "Hiervoor gaan we een csv gebruiken als bronbestand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4d7a1",
   "metadata": {},
   "source": [
    "## Extract\n",
    "\n",
    "In deze directory staat een zip file waarin deze csv is opgeslaan. \n",
    "Unzip deze file eerst en upload het naar het hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10681358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:43:47,570 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydoop.hdfs as hdfs\n",
    "    \n",
    "localFs = hdfs.hdfs(host='')\n",
    "clientFs = hdfs.hdfs(host='localhost', port=9000)\n",
    "\n",
    "if not clientFs.exists('ML'):\n",
    "    clientFs.create_directory('ML')\n",
    "    \n",
    "for f in clientFs.list_directory('ML'):\n",
    "    clientFs.delete(f['name'], True)\n",
    "\n",
    "localFs.copy('../Week 5/cars.csv', clientFs, 'ML/cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b7992",
   "metadata": {},
   "source": [
    "Maak nu een locale sparkcontext aan en lees dit bestand in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2336286",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-03-23 16:43:52,994 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2023-03-23 16:43:54,779 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows = 38531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:44:04,993 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|manufacturer_name|model_name|transmission| color|odometer_value|year_produced|engine_fuel|engine_has_gas|engine_type|engine_capacity|body_type|has_warranty|state|drivetrain|price_usd|is_exchangeable|location_region|number_of_photos|up_counter|feature_0|feature_1|feature_2|feature_3|feature_4|feature_5|feature_6|feature_7|feature_8|feature_9|duration_listed|\n",
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|           Subaru|   Outback|   automatic|silver|        190000|         2010|   gasoline|         False|   gasoline|            2.5|universal|       False|owned|       all|  10900.0|          False|   Минская обл.|               9|        13|    False|     True|     True|     True|    False|     True|    False|     True|     True|     True|             16|\n",
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[2]') \\\n",
    "                            .config(\"spark.driver.memory\", \"8g\") \\\n",
    "                            .config('spark.executor.memory', '2g') \\\n",
    "                            .appName('ML_cars') \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "# extract gedeelte\n",
    "df = spark.read.csv('ML/cars.csv', header=True, sep=',')\n",
    "print('Total rows = {}'.format(df.count()))\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1963092",
   "metadata": {},
   "source": [
    "De datastructuur van het csv is als volgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7c2042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer_name: string (nullable = true)\n",
      " |-- model_name: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- odometer_value: string (nullable = true)\n",
      " |-- year_produced: string (nullable = true)\n",
      " |-- engine_fuel: string (nullable = true)\n",
      " |-- engine_has_gas: string (nullable = true)\n",
      " |-- engine_type: string (nullable = true)\n",
      " |-- engine_capacity: string (nullable = true)\n",
      " |-- body_type: string (nullable = true)\n",
      " |-- has_warranty: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- drivetrain: string (nullable = true)\n",
      " |-- price_usd: string (nullable = true)\n",
      " |-- is_exchangeable: string (nullable = true)\n",
      " |-- location_region: string (nullable = true)\n",
      " |-- number_of_photos: string (nullable = true)\n",
      " |-- up_counter: string (nullable = true)\n",
      " |-- feature_0: string (nullable = true)\n",
      " |-- feature_1: string (nullable = true)\n",
      " |-- feature_2: string (nullable = true)\n",
      " |-- feature_3: string (nullable = true)\n",
      " |-- feature_4: string (nullable = true)\n",
      " |-- feature_5: string (nullable = true)\n",
      " |-- feature_6: string (nullable = true)\n",
      " |-- feature_7: string (nullable = true)\n",
      " |-- feature_8: string (nullable = true)\n",
      " |-- feature_9: string (nullable = true)\n",
      " |-- duration_listed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc8148",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "De transform stap is de meest complexe stap van de drie en kan uit een grote verscheidenheid van bewerkingen bestaan, zoals:\n",
    "* Dataformaten aanpassen\n",
    "* Vertalingen van tekst\n",
    "* Geencodeerde waarden aanpassen: 0/1 vs true/false of m/f vs male/female\n",
    "* Allerhande data-cleaning stappen\n",
    "* Encoderen (Ordinal of One-hot) van categorieke kolommen\n",
    "* Groeperen van data\n",
    "* Uitvoeren van berekeningen \n",
    "* ...\n",
    "\n",
    "Schrijf hieronder eerst zelf de code om de volgende stappen uit te voeren:\n",
    "* Omzetten naar integer van de kolommen: odometer_value, year_produced, engine_capacity, price_usd, number_of_photos, up_counter, duration_listed\n",
    "* Omzetten naar boolean van de kolommen: engine_has_gas, has_warranty, is_exchangeable, feature_0 tot en met 9\n",
    "* Bereken het aantal null en nan waarden per kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadd2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa4ab062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer_name: string (nullable = true)\n",
      " |-- model_name: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- odometer_value: integer (nullable = true)\n",
      " |-- year_produced: integer (nullable = true)\n",
      " |-- engine_fuel: string (nullable = true)\n",
      " |-- engine_has_gas: string (nullable = true)\n",
      " |-- engine_type: string (nullable = true)\n",
      " |-- engine_capacity: integer (nullable = true)\n",
      " |-- body_type: string (nullable = true)\n",
      " |-- has_warranty: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- drivetrain: string (nullable = true)\n",
      " |-- price_usd: integer (nullable = true)\n",
      " |-- is_exchangeable: string (nullable = true)\n",
      " |-- location_region: string (nullable = true)\n",
      " |-- number_of_photos: integer (nullable = true)\n",
      " |-- up_counter: integer (nullable = true)\n",
      " |-- feature_0: string (nullable = true)\n",
      " |-- feature_1: string (nullable = true)\n",
      " |-- feature_2: string (nullable = true)\n",
      " |-- feature_3: string (nullable = true)\n",
      " |-- feature_4: string (nullable = true)\n",
      " |-- feature_5: string (nullable = true)\n",
      " |-- feature_6: string (nullable = true)\n",
      " |-- feature_7: string (nullable = true)\n",
      " |-- feature_8: string (nullable = true)\n",
      " |-- feature_9: string (nullable = true)\n",
      " |-- duration_listed: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import IntegerType, BooleanType\n",
    "\n",
    "df = df_backup\n",
    "\n",
    "cols = ['odometer_value', 'year_produced', 'engine_capacity', 'price_usd', 'number_of_photos', 'up_counter', 'duration_listed']\n",
    "for c in cols:\n",
    "    #df = df.withColumn(c, f.col(c).cast(IntegerType()))\n",
    "    df = df.withColumn(c, f.col(c).cast('int'))\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be33225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- manufacturer_name: string (nullable = true)\n",
      " |-- model_name: string (nullable = true)\n",
      " |-- transmission: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- odometer_value: integer (nullable = true)\n",
      " |-- year_produced: integer (nullable = true)\n",
      " |-- engine_fuel: string (nullable = true)\n",
      " |-- engine_has_gas: boolean (nullable = true)\n",
      " |-- engine_type: string (nullable = true)\n",
      " |-- engine_capacity: integer (nullable = true)\n",
      " |-- body_type: string (nullable = true)\n",
      " |-- has_warranty: boolean (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- drivetrain: string (nullable = true)\n",
      " |-- price_usd: integer (nullable = true)\n",
      " |-- is_exchangeable: boolean (nullable = true)\n",
      " |-- location_region: string (nullable = true)\n",
      " |-- number_of_photos: integer (nullable = true)\n",
      " |-- up_counter: integer (nullable = true)\n",
      " |-- feature_0: boolean (nullable = true)\n",
      " |-- feature_1: boolean (nullable = true)\n",
      " |-- feature_2: boolean (nullable = true)\n",
      " |-- feature_3: boolean (nullable = true)\n",
      " |-- feature_4: boolean (nullable = true)\n",
      " |-- feature_5: boolean (nullable = true)\n",
      " |-- feature_6: boolean (nullable = true)\n",
      " |-- feature_7: boolean (nullable = true)\n",
      " |-- feature_8: boolean (nullable = true)\n",
      " |-- feature_9: boolean (nullable = true)\n",
      " |-- duration_listed: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['engine_has_gas', 'has_warranty', 'is_exchangeable', 'feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n",
    "for c in cols:\n",
    "    #df = df.withColumn(c, f.col(c).cast(BooleanType()))\n",
    "    df = df.withColumn(c, f.col(c).cast('boolean'))\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd83437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+-----+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|manufacturer_name|model_name|transmission|color|odometer_value|year_produced|engine_fuel|engine_has_gas|engine_type|engine_capacity|body_type|has_warranty|state|drivetrain|price_usd|is_exchangeable|location_region|number_of_photos|up_counter|feature_0|feature_1|feature_2|feature_3|feature_4|feature_5|feature_6|feature_7|feature_8|feature_9|duration_listed|\n",
      "+-----------------+----------+------------+-----+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|                0|         0|           0|    0|             0|            0|          0|             0|          0|             10|        0|           0|    0|         0|        0|              0|              0|               0|         0|        0|        0|        0|        0|        0|        0|        0|        0|        0|        0|              0|\n",
      "+-----------------+----------+------------+-----+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+-----+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nulls = df.select([f.count(f.when(f.col(c).isNull(), 1)).alias(c) for c in df.columns])  # die 1 dient om iets te hebben dat je kan tellen\n",
    "nulls.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cee12",
   "metadata": {},
   "source": [
    "In bovenstaande code kan je zien dat er slechts een aantal null-waarden in de dataset aanwezig zijn.\n",
    "Deze kunnen ingevuld worden door middel van een [imputer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Imputer.html).\n",
    "Hier laten we deze rijen echter gewoon vallen voor de eenvoud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653829e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38521"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.na.drop()\n",
    "df.count()  # bovenaan hadden we er 38531 dus zijn er inderdaad 10 weg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c3367",
   "metadata": {},
   "source": [
    "De oefening om de waarden in te vullen met een imputer (bvb door het gemiddelde) kan je hieronder doen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7eedb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oefening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a7e58",
   "metadata": {},
   "source": [
    "Bereken nu de volgende waarden van de beschikbare data:\n",
    "* Aantal autos per merk\n",
    "* Welke verschillende types van transmissie zijn er?\n",
    "* Marktaandeel (percentage) van de verschillende types motor?\n",
    "* Maximum prijs van elk merk\n",
    "* Wat zijn de vijf goedkoopste voertuigen met een automatische transmissie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99670921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|manufacturer_name|count|\n",
      "+-----------------+-----+\n",
      "|       Volkswagen| 4243|\n",
      "|            Lexus|  213|\n",
      "|           Jaguar|   53|\n",
      "|            Rover|  235|\n",
      "|           Lancia|   92|\n",
      "|             Jeep|  107|\n",
      "|       Mitsubishi|  887|\n",
      "|              ГАЗ|  200|\n",
      "|              Kia|  912|\n",
      "|             Mini|   68|\n",
      "|        Chevrolet|  435|\n",
      "|            Volvo|  721|\n",
      "|            Lifan|   47|\n",
      "|          Hyundai| 1116|\n",
      "|             LADA|  146|\n",
      "|        SsangYong|   79|\n",
      "|             Audi| 2468|\n",
      "|             Seat|  303|\n",
      "|         Cadillac|   43|\n",
      "|          Pontiac|   42|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# autos per merk\n",
    "df.groupby('manufacturer_name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed1f3bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|transmission|count|\n",
      "+------------+-----+\n",
      "|   automatic|12888|\n",
      "|  mechanical|25633|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|transmission|\n",
      "+------------+\n",
      "|   automatic|\n",
      "|  mechanical|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# types transmissie\n",
    "df.groupby('transmission').count().show()\n",
    "df.select('transmission').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5629e72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------------+\n",
      "|engine_type|count|       marktaandeel|\n",
      "+-----------+-----+-------------------+\n",
      "|   gasoline|25647| 0.6657926845097479|\n",
      "|     diesel|12874|0.33420731549025207|\n",
      "+-----------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# marktaandeel\n",
    "aantal_autos = df.count()\n",
    "df_aandeel = df.groupby('engine_type').count()\n",
    "df_aandeel.withColumn('marktaandeel', f.col('count')/aantal_autos).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0763a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|manufacturer_name|max(price_usd)|\n",
      "+-----------------+--------------+\n",
      "|       Volkswagen|         43999|\n",
      "|            Lexus|         48610|\n",
      "|           Jaguar|         50000|\n",
      "|            Rover|          9900|\n",
      "|           Lancia|          9500|\n",
      "|             Jeep|         43000|\n",
      "|       Mitsubishi|         31400|\n",
      "|              ГАЗ|         30000|\n",
      "|              Kia|         44700|\n",
      "|             Mini|         39456|\n",
      "|        Chevrolet|         49900|\n",
      "|            Volvo|         48200|\n",
      "|            Lifan|         15750|\n",
      "|          Hyundai|         45954|\n",
      "|             LADA|         13800|\n",
      "|        SsangYong|         15900|\n",
      "|             Audi|         46750|\n",
      "|             Seat|         18350|\n",
      "|         Cadillac|         25750|\n",
      "|          Pontiac|         10000|\n",
      "+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# maximum prijs per merk\n",
    "df.groupby('manufacturer_name').max('price_usd').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c60474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+---------+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|manufacturer_name|model_name|transmission| color|odometer_value|year_produced|engine_fuel|engine_has_gas|engine_type|engine_capacity|body_type|has_warranty|    state|drivetrain|price_usd|is_exchangeable|location_region|number_of_photos|up_counter|feature_0|feature_1|feature_2|feature_3|feature_4|feature_5|feature_6|feature_7|feature_8|feature_9|duration_listed|\n",
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+---------+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "|             Opel|     Omega|   automatic|  blue|        111222|         1987|   gasoline|         false|   gasoline|              2|    sedan|       false|emergency|      rear|      150|          false|   Минская обл.|               2|         1|     true|    false|    false|    false|    false|    false|    false|    false|    false|    false|             72|\n",
      "|            Rover|600-Series|   automatic|  grey|        420000|         1995|        gas|          true|   gasoline|              2|    sedan|       false|emergency|     front|      200|           true| Брестская обл.|               3|         2|    false|     true|    false|    false|     true|    false|    false|    false|    false|    false|             87|\n",
      "|            Mazda|  Millenia|   automatic|  blue|        150000|         1997|   gasoline|         false|   gasoline|              2|    sedan|       false|emergency|     front|      222|          false|   Минская обл.|               2|        13|    false|     true|     true|    false|     true|     true|     true|     true|     true|     true|             14|\n",
      "|            Mazda|   Xedos 9|   automatic| white|        150000|         1997|   gasoline|         false|   gasoline|              2|    sedan|       false|emergency|     front|      222|           true|   Минская обл.|               2|        30|    false|     true|     true|     true|     true|     true|     true|     true|     true|     true|             32|\n",
      "|       Mitsubishi|    Lancer|   automatic|silver|        290000|         1996|     diesel|         false|     diesel|              1|hatchback|       false|emergency|     front|      250|          false|   Минская обл.|               4|         5|    false|    false|    false|    false|    false|    false|    false|    false|    false|     true|             65|\n",
      "+-----------------+----------+------------+------+--------------+-------------+-----------+--------------+-----------+---------------+---------+------------+---------+----------+---------+---------------+---------------+----------------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# goedkoopste voertuigen met automatische transmissie\n",
    "df_cheapest = df.filter(f.col('transmission') == 'automatic').sort(f.col('price_usd').asc()).limit(5)\n",
    "\n",
    "df_cheapest.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35b2a40",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "In deze stap veronderstellen we dat we enkel de 5 goedkoopste auto's willen bewaren.\n",
    "Schrijf hieronder de benodigde code om de informatie van deze autos op te slaan in een json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7badc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cheapest.write.format('json').save('ML/result.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2bab6",
   "metadata": {},
   "source": [
    "Dit is een voorbeeld waarbij de resultaten worden opgeslaan in een bestand.\n",
    "Andere mogelijkheden zijn om het op te slaan in een SQL-database.\n",
    "Demo-code om dit te bereiken kan je [hier](https://kontext.tech/column/spark/395/save-dataframe-to-sql-databases-via-jdbc-in-pyspark) bekijken.\n",
    "Later in dit vak zullen we ook NoSQL-databases bekijken.\n",
    "Op dat moment zullen we zien hoe we de resultaten kunnen bewaren in dit type database beheersystemen (DBMS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d533bca",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Maak nu een ML-pipeline waarbij geprobeerd wordt om de verkoopsprijs zo goed mogelijk te voorspellen.\n",
    "Bereken voor de pipelijn op te stellen de aantal unieke waarden in de string kolommen.\n",
    "Maak nu drie lijsten aan:\n",
    "* De kolommen met meer dan 100 unieke waarden (gaan we droppen)\n",
    "* De kolommen met meer dan 10 unieke waarden (gaan we encoderen met ordinal encoding)\n",
    "* De overige kolommen gaan we met one-hot encoding doen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28ce09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manufacturer_name 55\n",
      "model_name 1116\n",
      "transmission 2\n",
      "color 12\n",
      "engine_fuel 5\n",
      "engine_type 2\n",
      "body_type 12\n",
      "state 3\n",
      "drivetrain 3\n",
      "location_region 6\n",
      "int ['odometer_value', 'year_produced', 'engine_capacity', 'number_of_photos', 'up_counter', 'duration_listed']\n",
      "bool ['engine_has_gas', 'has_warranty', 'is_exchangeable', 'feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9']\n"
     ]
    }
   ],
   "source": [
    "for c in [item[0] for item in df.dtypes if item[1].startswith('string')]:\n",
    "    print(c, df.select(c).distinct().count())\n",
    "    \n",
    "# drop cols with more than 100 options\n",
    "cols_to_drop = ['model_name']\n",
    "# cols with more than 10 options:\n",
    "cols_ordinal = ['manufacturer_name', 'color', 'body_type']\n",
    "# cols with less than 10 options\n",
    "cols_onehot = ['transmission', 'engine_fuel', 'engine_type', 'state', 'drivetrain', 'location_region']\n",
    "\n",
    "cols_int = [item[0] for item in df.dtypes if item[1].startswith('int')]\n",
    "cols_int.remove('price_usd')\n",
    "print('int', cols_int)\n",
    "cols_bool = [item[0] for item in df.dtypes if item[1].startswith('bool')]\n",
    "print('bool', cols_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78def05",
   "metadata": {},
   "source": [
    "Doe dit aan de hand van een pipeline waarbij je minstens de volgende stappen uitvoert:\n",
    "* Gebruik de vector assembler om alle integer kolommen te groeperen in een kolom met de naam 'intfeatures' (let op dat je niet de prijs kolom mee neemt in de berekening)\n",
    "* Voeg 3de-graads polynomiale uitbreiding toe van de numerieke kolommen\n",
    "* Voer normalisatie uit van elke feature in deze kolom zodat het gemiddelde 0 is en en de stddev 1\n",
    "* Voeg ordinal encoding van de kolommen met tussen de 10 en 100 unieke waarden toe\n",
    "* Voeg onehot encoding van de kolommen met minder dan 10 unieke waarden toe\n",
    "* Gebruik opnieuw de vectorassembler om alle kolommen (intfeatures, boolean, onehot en ordinal kolommen) samen te voegen in 1 kolom 'features'\n",
    "* Train een regressor (zie de api voor de mogelijkheden) en train het met de 'features' kolom als features en price_usd als targets\n",
    "* Evalueer het model door de root mean squared error en verklaarde variabiliteit te berekenen. Gebruik hiervoor de random_split functie om de dataset te splitsen in train en test data\n",
    "* Gebruik een cross-validator om op zoek te gaan naar de beste parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81435d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2398.835009943527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 421:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30737373.27843988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, PolynomialExpansion, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# splitsen in train en test (stap 8)\n",
    "(train,test) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# stap 1\n",
    "stap1 = VectorAssembler(inputCols=cols_int, outputCol='intfeatures')\n",
    "\n",
    "# stap 2\n",
    "stap2 = PolynomialExpansion(degree=3, inputCol='intfeatures', outputCol='exp_int_features')\n",
    "\n",
    "# stap 3 -> gemiddelde 0 is en stddev = 1\n",
    "stap3 = StandardScaler(inputCol='exp_int_features', outputCol='scaled_int_features', withMean=True)\n",
    "# 2 features x en y en graad 3\n",
    "# features berekenen x, x^2, x^3, y, y^2, y^3, x*y, x^2*y, y^2*x\n",
    "\n",
    "# stap 4\n",
    "cols_ordinal_out = [x + '_out' for x in cols_ordinal]\n",
    "stap4 = StringIndexer(inputCols=cols_ordinal, outputCols=cols_ordinal_out)\n",
    "# in de fit stap wordt hier berekend welk woord met welk getal overeenkomt -> met de labels attribuut kan je de omgekeerde operatie doen\n",
    "\n",
    "# stap5\n",
    "#onehot encoder verwacht iets dat geordinalencoded is\n",
    "cols_onehot_out1 = [x + '_tmp' for x in cols_onehot]\n",
    "cols_onehot_out2 = [x + '_out' for x in cols_onehot]\n",
    "stap5_1 = StringIndexer(inputCols=cols_onehot, outputCols=cols_onehot_out1)\n",
    "stap5_2 = OneHotEncoder(inputCols=cols_onehot_out1, outputCols=cols_onehot_out2)\n",
    "\n",
    "# stap 6\n",
    "cols_features = cols_onehot_out2 + cols_ordinal_out + ['scaled_int_features'] + cols_bool  # lijsten extenden\n",
    "stap6 = VectorAssembler(inputCols=cols_features, outputCol='features')\n",
    "\n",
    "# stap7\n",
    "regressor = RandomForestRegressor(featuresCol='features', labelCol='price_usd', predictionCol='preds', maxBins=60)\n",
    "\n",
    "pipeline = Pipeline(stages=[stap1, stap2, stap3, stap4, stap5_1, stap5_2, stap6, regressor])\n",
    "\n",
    "# fit the pipeline\n",
    "model = pipeline.fit(train)  # in het geval van niet splitsen stond hier en de lijn eronder df ipv train en test\n",
    "preds = model.transform(test)\n",
    "#preds.show(1,truncate=False)\n",
    "\n",
    "evaluator1 = RegressionEvaluator(labelCol='price_usd',predictionCol='preds', metricName='rmse')\n",
    "evaluator2 = RegressionEvaluator(labelCol='price_usd',predictionCol='preds', metricName='var')\n",
    "\n",
    "print(evaluator1.evaluate(preds))\n",
    "print(evaluator2.evaluate(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7aa958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "[Stage 425:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 2398.835009943527\n",
      "Explained variance = 37692558.83460832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# iets oudere manier voor evaluatie te doen (rdd-based)\n",
    "\n",
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "true_and_pred = preds.select('price_usd', 'preds').rdd.map(lambda x: (float(x[0]), float(x[1]))) \n",
    "true_and_pred.collect()\n",
    "metrics = RegressionMetrics(true_and_pred)\n",
    "\n",
    "print(\"RMSE =\", metrics.rootMeanSquaredError)\n",
    "print(\"Explained variance =\",metrics.explainedVariance)  # dit geeft niet exact dezelfde waarde als hierboven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a2d6f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# grid met opties voor parameters\n",
    "paramGrid = ParamGridBuilder().addGrid(regressor.numTrees, [5, 10]).build()\n",
    "# aan het grid kan je ook parameters van de andere stappen toevoegen\n",
    "#paramGrid = ParamGridBuilder().addGrid(regressor.numTrees, [5, 10]).addGrid(stap2.degree,[2,3]).build()\n",
    "\n",
    "# dit is wat we gaan optimaliseren\n",
    "evaluator = RegressionEvaluator(labelCol='price_usd',predictionCol='preds', metricName='rmse')\n",
    "\n",
    "tvs = TrainValidationSplit(estimator=pipeline, evaluator=evaluator, estimatorParamMaps=paramGrid, parallelism=1)\n",
    "\n",
    "cvModel = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d262ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beste parameters van het beste model\n",
    "cvModel.bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.bestModel.save(\"ML/model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
